# üöó An√°lise de Sentimentos em Redes Sociais: Aplica√ß√µes no Setor Automotivo

## üáßüá∑ Vis√£o Geral do Projeto (Portugu√™s)

Este projeto, desenvolvido como Trabalho de Conclus√£o de Curso (TCC) no MBA em Intelig√™ncia Artificial e Big Data, prop√µe e implementa um *pipeline* completo de An√°lise de Sentimentos (Sentiment Analysis) focado no setor automotivo brasileiro. O principal objetivo √© transformar o vasto volume de dados n√£o estruturados gerados por consumidores em redes sociais em intelig√™ncia de mercado acion√°vel, auxiliando tanto a decis√£o de compra do consumidor final quanto a estrat√©gia de produto das fabricantes.

---

### Stack Tecnol√≥gico

A arquitetura da solu√ß√£o integra bibliotecas de Data Science e plataformas de desenvolvimento modernas:

| Categoria | Tecnologia | Finalidade | 
 | ----- | ----- | ----- | 
| **Linguagem** | Python | Linguagem principal para desenvolvimento do *pipeline* e do *dashboard*. | 
| **NLP/Modelagem** | Hugging Face Transformers (BERTimbau) | Classifica√ß√£o contextual de sentimentos em portugu√™s. | 
| **Visualiza√ß√£o** | Streamlit, Plotly Express | Cria√ß√£o do *dashboard* interativo e dos gr√°ficos de distribui√ß√£o. | 
| **Processamento de Dados** | Pandas, scikit-learn (TF-IDF) | Manipula√ß√£o de DataFrames e extra√ß√£o de t√≥picos relevantes. | 
| **Banco de Dados** | MySQL | Persist√™ncia do hist√≥rico de an√°lises e resumos t√©cnicos. | 

---

### Metodologia e Tecnologias

A solu√ß√£o √© baseada na integra√ß√£o de t√©cnicas avan√ßadas de Processamento de Linguagem Natural (PLN) com uma arquitetura de *dashboard* interativo:

* **Coleta de Dados:** Os dados de texto (tweets) s√£o extra√≠dos da plataforma X (antigo Twitter), utilizando modelos de busca espec√≠ficos para men√ß√µes a modelos de ve√≠culos.

* **Processamento de Linguagem Natural (PLN):** A an√°lise de sentimentos √© realizada utilizando o modelo **BERTimbau**, um modelo Transformer pr√©-treinado especificamente para a l√≠ngua portuguesa. O uso de um modelo baseado em *embeddings* garante uma classifica√ß√£o contextual e de alta precis√£o dos sentimentos em tr√™s categorias: POSITIVO, NEGATIVO e NEUTRO.

* **Gera√ß√£o de T√≥picos:** √â aplicada a t√©cnica TF-IDF (Term Frequency-Inverse Document Frequency) para identificar e extrair as palavras-chave e t√≥picos mais relevantes associados a cada polaridade de sentimento (positiva e negativa).

* **Visualiza√ß√£o:** Os resultados s√£o apresentados em um *dashboard* interativo desenvolvido com **Streamlit** e **Plotly**, permitindo que o usu√°rio visualize a distribui√ß√£o percentual dos sentimentos e as principais tend√™ncias de aceita√ß√£o e rejei√ß√£o de modelos de ve√≠culos em tempo real.

* **Persist√™ncia:** O hist√≥rico de todas as an√°lises geradas √© armazenado em um banco de dados **MySQL** (`db_connector.py`), garantindo a rastreabilidade e a capacidade de compara√ß√£o entre modelos ao longo do tempo.

---

### Pipeline do Projeto

O fluxo de trabalho (pipeline) da aplica√ß√£o segue rigorosamente as etapas de um projeto de Data Science:

1. **Coleta de Dados (`coleta.py`):** Captura de dados brutos (tweets) utilizando a palavra-chave do modelo de ve√≠culo.

2. **Pr√©-processamento (`preprocessamento.py`):** Limpeza dos textos, remo√ß√£o de *stopwords* e normaliza√ß√£o.

3. **Modelagem (`app.py`):** Classifica√ß√£o do sentimento (POSITIVO/NEGATIVO/NEUTRO) por tweet, utilizando o modelo BERTimbau.

4. **Extra√ß√£o de T√≥picos (`app.py`):** Aplica√ß√£o de TF-IDF para sumarizar as raz√µes por tr√°s dos sentimentos positivos e negativos.

5. **Persist√™ncia (`db_connector.py`):** Salvamento da s√≠ntese, distribui√ß√£o de sentimentos e *timestamp* no hist√≥rico.

6. **Visualiza√ß√£o (`app.py`):** Renderiza√ß√£o dos resultados no dashboard Streamlit, incluindo gr√°ficos de barras e comparativos.

---

### Execu√ß√£o do Projeto

Para rodar o projeto localmente, siga os seguintes passos:

1. **Clonar Reposit√≥rio:** `git clone https://github.com/ricardoaraujo75/tcc-analise-sentimentos-autos`

2. **Instalar Depend√™ncias:** Certifique-se de ter as bibliotecas Python listadas no `requirements.txt` (incluindo `streamlit`, `pandas`, `transformers`, `plotly`, `mysql-connector-python`, `scikit-learn`).

3. **Configurar Banco de Dados:** Garanta que a conex√£o com o MySQL (definida em `db_connector.py`) esteja ativa e as tabelas necess√°rias criadas.

4. **Executar o Dashboard:** `streamlit run app.py`

---

### Resultado Esperado

O resultado final √© uma ferramenta de apoio √† decis√£o capaz de gerar uma **S√≠ntese Integrada de Mercado e Sentimentos** para qualquer modelo de ve√≠culo pesquisado. Espera-se que o usu√°rio possa:

* **Visualizar rapidamente** a distribui√ß√£o percentual de sentimentos (Positivo vs. Negativo vs. Neutro).

* **Identificar os principais t√≥picos** que geram aceita√ß√£o (vantagens) e rejei√ß√£o (problemas cr√¥nicos) do ve√≠culo, baseados na voz do consumidor.

* **Comparar a performance** de sentimento de dois modelos distintos ao longo do hist√≥ria.

---

# üöó Sentiment Analysis in Social Media: Applications in the Automotive Sector

## üá∫üá∏ Project Overview (English)

This project, developed as a Final Paper (TCC) for the MBA in Artificial Intelligence and Big Data, proposes and implements a complete Sentiment Analysis pipeline focused on the Brazilian automotive sector. The main goal is to transform the vast volume of unstructured data generated by consumers on social media into actionable market intelligence, supporting both the end consumer's purchase decision and the manufacturers' product strategy.

---

### Technology Stack

The solution architecture integrates modern Data Science libraries and development platforms:

| Categoria | Technology | Purpose | 
 | ----- | ----- | ----- | 
| **Language** | Python | Main language for developing the pipeline and dashboard. | 
| **NLP/Modeling** | Hugging Face Transformers (BERTimbau) | Contextual sentiment classification in Portuguese. | 
| **Visualization** | Streamlit, Plotly Express | Creation of the interactive dashboard and distribution charts. | 
| **Data Processing** | Pandas, scikit-learn (TF-IDF) | DataFrame manipulation and extraction of relevant topics. | 
| **Database** | MySQL | Persistence of analysis history and technical summaries. | 

---

### Methodology and Technologies

The solution is based on integrating advanced Natural Language Processing (NLP) techniques with an interactive dashboard architecture:

* **Data Collection:** Text data (tweets) is extracted from the platform X (formerly Twitter), using specific search queries for vehicle model mentions.

* **Natural Language Processing (NLP):** Sentiment analysis is performed using the **BERTimbau** model, a Transformer model pre-trained specifically for the Portuguese language. The use of an *embeddings*-based model ensures a contextual and high-accuracy classification of sentiments into three categories: POSITIVE, NEGATIVE, and NEUTRAL.

* **Topic Generation:** The TF-IDF (Term Frequency-Inverse Document Frequency) technique is applied to identify and extract the most relevant keywords and topics associated with each sentiment polarity (positive and negative).

* **Visualization:** The results are presented in an interactive dashboard developed with **Streamlit** and **Plotly**, allowing the user to visualize the percentage distribution of sentiments and the main trends in acceptance and rejection of vehicle models in real-time.

* **Persist√™ncia:** The history of all generated analyses is stored in a **MySQL** database (`db_connector.py`), ensuring traceability and the ability to compare models over time.

---

### Project Pipeline

The application's workflow (pipeline) strictly follows the steps of a Data Science project:

1. **Data Collection (`coleta.py`):** Capturing raw data (tweets) using the vehicle model keyword.

2. **Pre-processing (`preprocessamento.py`):** Text cleaning, removal of stop words, and normalization.

3. **Modelagem (`app.py`):** Sentiment classification (POSITIVO/NEGATIVO/NEUTRO) per tweet, using the BERTimbau model.

4. **Topic Extraction (`app.py`):** Application of TF-IDF to summarize the reasons behind positive and negative sentiments.

5. **Persistence (`db_connector.py`):** Saving the synthesis, sentiment distribution, and timestamp to the history.

6. **Visualiza√ß√£o (`app.py`):** Rendering the results on the Streamlit dashboard, including bar charts and comparisons.

---

### Project Execution

To run the project locally, follow these steps:

1. **Clone Repository:** `git clone https://github.com/ricardoaraujo75/tcc-analise-sentimentos-autos`

2. **Install Dependencies:** Ensure you have the Python libraries listed in `requirements.txt` (including `streamlit`, `pandas`, `transformers`, `plotly`, `mysql-connector-python`, `scikit-learn`).

3. **Configure Database:** Ensure the MySQL connection (defined in `db_connector.py`) is active and the necessary tables are created.

4. **Execute the Dashboard:** `streamlit run app.py`

---

### Expected Outcome

The final result is a decision support tool capable of generating an **Integrated Market and Sentiment Synthesis** for any researched vehicle model. The user is expected to be able to:

* **Quickly visualize** the percentage distribution of sentiments (Positive vs. Negative vs. Neutral).

* **Identify the main topics** that generate acceptance (advantages) and rejection (chronic issues) of the vehicle, based on the consumer's voice.

* **Compare the sentiment performance** of two distinct models over time.

---

üìÑ **Autor:** Ricardo Ara√∫jo

üéì **MBA em Intelig√™ncia Artificial e Big Data ‚Äì USP/ICMC**

üìÖ **Ano:** 2025