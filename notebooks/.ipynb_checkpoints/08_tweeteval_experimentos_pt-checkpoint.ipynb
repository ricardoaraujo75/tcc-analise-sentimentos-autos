{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a863b3a8",
   "metadata": {},
   "source": [
    "# Experimentos com TweetEval e Modelos Pré-Treinados em Português\n",
    "\n",
    "Este notebook realiza testes de análise de sentimentos utilizando modelos disponíveis no Hugging Face, incluindo TweetEval e modelos em português (ex.: BERTimbau).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd1c3ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2409234625.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install tiktoken\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio transformers datasets tiktoken protobuf --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539495f9",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67963bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "print('bibliotecas importadas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eca0d91-d1a8-4b8c-9b8b-b3b9d3273c0a",
   "metadata": {},
   "source": [
    "## Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d5589d-7507-47d2-bf82-87b7a940851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "login(\"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\")\n",
    "\n",
    "print('login realizado.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a94350",
   "metadata": {},
   "source": [
    "## Carregando modelo multilíngue (ex.: BERT Multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "sentiment_pipeline = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "exemplo = 'O HB20 é um carro econômico, mas tem pouco espaço interno.'\n",
    "print(sentiment_pipeline(exemplo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d3da3",
   "metadata": {},
   "source": [
    "## Carregando modelo em Português (BERTimbau + fine-tuning para sentimentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_pt = 'cardiffnlp/twitter-xlm-roberta-base-sentiment'\n",
    "tokenizer_pt = AutoTokenizer.from_pretrained(model_name_pt)\n",
    "model_pt = AutoModelForSequenceClassification.from_pretrained(model_name_pt)\n",
    "\n",
    "sentiment_pipeline_pt = pipeline('sentiment-analysis', model=model_pt, tokenizer=tokenizer_pt)\n",
    "\n",
    "exemplo_pt = 'O Onix tem bom consumo, mas o espaço traseiro poderia ser melhor.'\n",
    "print(sentiment_pipeline_pt(exemplo_pt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53e199",
   "metadata": {},
   "source": [
    "## Testando com o dataset TweetEval (sentiment - inglês)\n",
    "⚠️ Nota: TweetEval está em inglês, mas serve como referência inicial de benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('tweet_eval', 'sentiment')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36ddbb",
   "metadata": {},
   "source": [
    "### Exemplo de avaliação com TweetEval (inglês)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992fbab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplos = dataset['test']['text'][:5]\n",
    "for texto in exemplos:\n",
    "    print(texto)\n",
    "    print(sentiment_pipeline(texto))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e0caa",
   "metadata": {},
   "source": [
    "## Avaliação em Português\n",
    "Exemplo com frases simuladas sobre carros (HB20, Onix, Argo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81032a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "frases_pt = [\n",
    "    'O HB20 é econômico, mas o acabamento poderia ser melhor.',\n",
    "    'O Onix é muito confortável e tem ótimo custo-benefício.',\n",
    "    'O Argo apresenta falhas no motor segundo alguns usuários.'\n",
    "]\n",
    "\n",
    "for frase in frases_pt:\n",
    "    print(frase)\n",
    "    print(sentiment_pipeline_pt(frase))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dbcb69",
   "metadata": {},
   "source": [
    "## Próximos passos\n",
    "- Expandir testes para coleções maiores de tweets/reclamações.\n",
    "- Comparar métricas de performance entre TweetEval (inglês) e modelos PT-BR.\n",
    "- Integrar resultados com o banco de dados e dashboard.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
