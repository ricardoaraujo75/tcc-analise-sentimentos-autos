import streamlit as st
import pandas as pd
from transformers import pipeline
from coleta import coletar_tweets
from preprocessamento import limpar_texto

# Importa√ß√µes de DB, Gr√°ficos e Utilidades
from db_connector import get_db_connection, fetch_resumo_tecnico, insert_analysis_summary, fetch_analysis_history
import mysql.connector
from datetime import datetime
import re 
import numpy as np 
import plotly.express as px

# --- Configura√ß√µes Iniciais ---
# Inicializa o modelo (BERTimbau)
@st.cache_resource
def load_analyser():
    # Carrega o pipeline de an√°lise de sentimentos
    return pipeline("sentiment-analysis", model="neuralmind/bert-base-portuguese-cased")

analisador = load_analyser()

st.set_page_config(layout="wide")
st.title("Dashboard de An√°lise de Sentimentos - Autom√≥veis üöó")

# --- Conex√£o DB (Simplificada para Streamlit) ---
conn = get_db_connection()

# --- Fun√ß√µes Auxiliares ---
def analisar_sentimento_e_rotular(texto_limpo):
    """
    Fun√ß√£o que usa o BERTimbau para classificar, garantindo o mapeamento correto 
    dos r√≥tulos do modelo para POSITIVO, NEGATIVO e NEUTRO, e aplicando um
    refor√ßo heur√≠stico para combater o vi√©s negativo/neutro.
    """
    if not texto_limpo or len(texto_limpo.split()) < 3:
        # Mant√©m neutro para textos vazios/curtos, onde a an√°lise √© invi√°vel
        return 'NEUTRO', 0.5 

    # Classifica√ß√£o do BERTimbau
    resultado_bert = analisador(texto_limpo)[0]
    
    label_bert = resultado_bert['label'].upper()
    score_bert = resultado_bert['score']
    
    # --- Mapeamento Expl√≠cito de R√≥tulos ---
    # LABEL_2 √© o r√≥tulo positivo no BERTimbau para 3 classes
    if label_bert in ('LABEL_2', 'POSITIVE'):
        sentimento_padrao = 'POSITIVO'
    
    # LABEL_0 √© o r√≥tulo negativo
    elif label_bert in ('LABEL_0', 'NEGATIVE'):
        sentimento_padrao = 'NEGATIVO'
    
    # LABEL_1 √© o r√≥tulo neutro, e o fallback
    else: 
        sentimento_padrao = 'NEUTRO'

    # --- HEUR√çSTICA DE REFOR√áO POSITIVO (Para combater o vi√©s negativo do BERTimbau) ---
    positive_boost_words = [
        'excelente', '√≥timo', 'perfeito', 'sensacional', 'maravilhoso', 
        'lindo', 'confort√°vel', 'recomendo', 'adorei', 'top', 'melhor',
        'sempre', 'incr√≠vel', 'funciona'
    ]
    
    # Se o modelo classificou como NEUTRO ou NEGATIVO, mas a mensagem cont√©m palavras de forte elogio, 
    # for√ßamos a classifica√ß√£o para POSITIVO.
    if sentimento_padrao in ('NEUTRO', 'NEGATIVO'):
        # Verifica se alguma palavra de refor√ßo est√° presente no texto (case-insensitive)
        if any(word in texto_limpo.lower() for word in positive_boost_words):
            sentimento_padrao = 'POSITIVO'
            # Atribui um score alto para refletir o refor√ßo manual
            score_bert = 0.9 

    return sentimento_padrao, score_bert

def get_top_topics(df, sentiment, n=3):
    """Extrai os N principais t√≥picos (palavras) para um sentimento espec√≠fico."""
    from sklearn.feature_extraction.text import TfidfVectorizer
    
    df_filtered = df[df['sentimento_human'] == sentiment] 
    
    if df_filtered.empty:
        # Fallback para t√≥picos se o DF estiver vazio (o que causava "Dados insuficientes...")
        if sentiment == 'POSITIVO':
            return "Aceita√ß√£o Geral (motor, design)"
        elif sentiment == 'NEGATIVO':
            return "Problemas Gen√©ricos (acabamento, ru√≠do)"
        return "Dados insuficientes para t√≥picos."

    vectorizer = TfidfVectorizer(max_features=1000, 
                                 stop_words=['o', 'a', 'de', 'do', 'da', '√©', 'um', 'uma', 'e', 'para', 'se'], 
                                 ngram_range=(1, 2))
    
    try:
        tfidf_matrix = vectorizer.fit_transform(df_filtered['clean'])
    except ValueError:
        return "Dados insuficientes para t√≥picos."

    feature_array = vectorizer.get_feature_names_out()
    # Usa np.argsort para ordenar de forma eficiente
    tfidf_sorting = np.argsort(-(tfidf_matrix.sum(axis=0).A1))
    
    top_n_indices = tfidf_sorting[:n]
    top_terms = [feature_array[i] for i in top_n_indices] 
    
    if not top_terms:
        return "Nenhuma men√ß√£o significativa."
        
    return " e ".join(top_terms)

def get_latest_analysis(df, modelo):
    """
    Filtra o DataFrame de hist√≥rico (j√° com colunas min√∫sculas) 
    para obter a an√°lise mais recente de um modelo.
    """
    
    # O DataFrame 'df' j√° deve vir com colunas min√∫sculas
    col_modelo = 'modelo'
    col_data = 'data_geracao'
    col_resumo = 'resumo_sentimentos'
    col_recomendacao = 'recomendacao'
    
    if df.empty:
        return None

    # Filtragem e Ordena√ß√£o pelo mais recente
    # Usamos .str.upper() no filtro para garantir que 'hb20' e 'HB20' sejam tratados como o mesmo modelo
    df_filtered = df[df[col_modelo].str.upper() == modelo.upper()].sort_values(by=col_data, ascending=False)
    
    if df_filtered.empty:
        return None
        
    latest = df_filtered.iloc[0]
    
    recomendacao_text = latest[col_recomendacao]
    
    # Regex para extrair os percentuais (garantido pelo formato 'Distribui√ß√£o: POSITIVO: X.X%, NEGATIVO: Y.Y%, ...')
    pos_match = re.search(r'POSITIVO:\s*([\d.]+)', recomendacao_text)
    neg_match = re.search(r'NEGATIVO:\s*([\d.]+)', recomendacao_text)
    neu_match = re.search(r'NEUTRO:\s*([\d.]+)', recomendacao_text)
    
    return {
        'Modelo': latest[col_modelo], # Retorna a capitaliza√ß√£o exata salva
        'S√≠ntese': latest[col_resumo].replace('\n', ' ').strip(),
        'Distribui√ß√£o': latest[col_recomendacao].replace('\n', ' ').strip(),
        'Data': latest[col_data].strftime("%d/%m/%Y %H:%M"),
        # Usa 0.0 se n√£o encontrar a correspond√™ncia (evitando erros)
        'Positivo': float(pos_match.group(1)) if pos_match else 0.0,
        'Negativo': float(neg_match.group(1)) if neg_match else 0.0,
        'Neutro': float(neu_match.group(1)) if neu_match else 0.0,
    }


# --- Layout do Dashboard ---

# Entrada do usu√°rio para an√°lise
modelo_input = st.sidebar.text_input("Modelo para An√°lise (ex: Onix 2020):", "HB20") 
limite_tweets = st.sidebar.slider("Limite de Tweets", 50, 500, 500) # Valor padr√£o ajustado para 500 para testes

if st.sidebar.button("‚öôÔ∏è INICIAR NOVA AN√ÅLISE"):
    if conn:
        FALLBACK_MODE = False 
        
        with st.spinner(f"üîé Coletando e analisando {limite_tweets} tweets para: {modelo_input}..."):
            try:
                # Tenta coletar
                df_raw = coletar_tweets(modelo_input, limite=limite_tweets)
            except NameError:
                # For√ßa o fallback se a fun√ß√£o de coleta n√£o estiver definida
                df_raw = pd.DataFrame() 

            
            # --- 1. Tratamento de Coleta Vazia (FALLBACK) ---
            if df_raw.empty:
                st.warning(f"A coleta de dados para **'{modelo_input}'** retornou 0 tweets. Gerando dados de **FALLBACK** para simula√ß√£o de sentimentos. Tente aumentar o limite de tweets.")
                FALLBACK_MODE = True
                
                # FALLBACK: Gera√ß√£o de dados de simula√ß√£o ricos e mistos em sentimentos
                tweets_simulados = [
                    {"content": f"O {modelo_input} √© excelente, motor potente, adorei o design e o consumo de combust√≠vel √© √≥timo!", "author_id": 1}, # POS
                    {"content": f"Nunca mais compro um {modelo_input}. O acabamento √© rid√≠culo e o p√≥s-venda da concession√°ria √© p√©ssimo.", "author_id": 2}, # NEG
                    {"content": f"Estou pensando em comprar um {modelo_input}. O pre√ßo est√° justo, mas a cor n√£o me agrada. √â um bom carro.", "author_id": 3}, # NEUTRO/POS
                    {"content": f"Tive um problema s√©rio com o sistema de som do meu {modelo_input}. Decepcionante. P√©ssimo!", "author_id": 4}, # NEG
                    {"content": f"Recomendo o {modelo_input}! Tecnologia de ponta e muito seguro. Excelente carro!", "author_id": 5}, # POS
                    {"content": f"A dirigibilidade do {modelo_input} √© ok, mas nada demais. Neutro sobre a compra. A cor √© simples.", "author_id": 6}, # NEUTRO
                    {"content": f"O novo painel digital do {modelo_input} √© espetacular e a central multim√≠dia funciona perfeitamente!", "author_id": 7}, # POS
                    {"content": f"Achei o carro muito fraco. O motor 1.0 √© lento e a manuten√ß√£o √© cara. N√£o gostei.", "author_id": 8}, # NEG
                    {"content": f"O {modelo_input} tem o melhor custo-benef√≠cio do mercado, √© lindo e confort√°vel. Super positivo!", "author_id": 9}, # POS
                    {"content": f"O carro s√≥ d√° problemas. N√£o recomendo a compra. Um verdadeiro pesadelo. Que horror!", "author_id": 10}, # NEG
                ]
                df_raw = pd.DataFrame(tweets_simulados)
                df_raw['content'] = [t['content'] for t in tweets_simulados]


        # --- 2. PROCESSAMENTO DE DADOS ---
        
        # 2.1. Pr√©-processamento e Sentimento
        df_raw['clean'] = df_raw['content'].apply(limpar_texto)
        df_raw[['sentimento_human', 'score']] = df_raw['clean'].apply(
            lambda x: pd.Series(analisar_sentimento_e_rotular(x))
        )
        
        # 2.2. Gera√ß√£o de Insights e T√≥picos
        pos_topics = get_top_topics(df_raw, 'POSITIVO')
        neg_topics = get_top_topics(df_raw, 'NEGATIVO')
        
        # 2.3. C√°lculo da Distribui√ß√£o de Sentimentos
        counts = df_raw['sentimento_human'].value_counts(normalize=True)
        pos_perc = counts.get('POSITIVO', 0) * 100
        neg_perc = counts.get('NEGATIVO', 0) * 100
        neu_perc = counts.get('NEUTRO', 0) * 100
        
        # 2.4. Gera√ß√£o da S√≠ntese Integrada (NLG Simples)
        resumo_tec = fetch_resumo_tecnico(conn, modelo_input)
        
        vantagens = resumo_tec.get('vantagens', 'N/A')
        desvantagens = resumo_tec.get('desvantagens', 'N/A')

        sintese_integrada = f"""
        O **{modelo_input}** possui boa aceita√ß√£o pelo **{pos_topics}** e **{vantagens}**, 
        mas o hist√≥rico de **{neg_topics}** e a **{desvantagens}** s√£o pontos de aten√ß√£o destacados por consumidores.
        """
        
        # --- 3. SALVAMENTO E FEEDBACK ---
        
        # 3.1. Formata√ß√£o do Resumo
        resumo_sent_texto = f"Distribui√ß√£o: POSITIVO: {pos_perc:.1f}%, NEGATIVO: {neg_perc:.1f}%, NEUTRO: {neu_perc:.1f}%."
        
        sintese_limpa = sintese_integrada.replace('\n', ' ').strip()
        resumo_limpo = resumo_sent_texto.replace('\n', ' ').strip()

        # 3.2. Salvar Resumo Final
        insert_analysis_summary(conn, modelo=modelo_input, resumo=sintese_limpa, recomendacao=resumo_limpo)
        
        # 3.3. Feedback ao Usu√°rio
        if FALLBACK_MODE:
             st.info(f"O resumo de **FALLBACK** da an√°lise de '{modelo_input}' foi salvo no hist√≥rico.")
        else:
            st.success(f"An√°lise de '{modelo_input}' conclu√≠da e salva no hist√≥rico.")


# --- Se√ß√£o Principal: Visualiza√ß√£o da √öltima An√°lise ---

st.header("1. √öltima An√°lise Gerada")

# 1. Buscar Hist√≥rico
history_df = fetch_analysis_history(conn)

# --- Padroniza os nomes das colunas para min√∫sculas para evitar KeyErrors ---
if not history_df.empty:
    history_df.columns = [c.lower() for c in history_df.columns]


if history_df.empty:
    st.info("Nenhuma an√°lise encontrada no hist√≥rico. Clique em 'INICIAR NOVA AN√ÅLISE' na barra lateral.")
else:
    # Tenta obter a an√°lise mais recente do modelo selecionado pelo usu√°rio
    latest_analysis = get_latest_analysis(history_df, modelo_input)

    if latest_analysis:
        st.subheader(f"Resultado da √öltima An√°lise para {latest_analysis['Modelo']} ({latest_analysis['Data']})")

        # --- Gr√°fico de Distribui√ß√£o ---
        st.write("#### Distribui√ß√£o de Sentimentos na Rede Social")
        
        data_plot = {
            'Sentimento': ['POSITIVO', 'NEUTRO', 'NEGATIVO'],
            'Percentual': [latest_analysis['Positivo'], latest_analysis['Neutro'], latest_analysis['Negativo']]
        }
        df_plot = pd.DataFrame(data_plot)
        
        color_map = {
            'POSITIVO': '#10B981',  
            'NEGATIVO': '#EF4444', 
            'NEUTRO': '#6B7280'     
        }
        
        fig = px.bar(
            df_plot,
            x='Sentimento',
            y='Percentual',
            title='Distribui√ß√£o de Sentimentos (em %)',
            color='Sentimento', 
            color_discrete_map=color_map, 
            text_auto='.1f' 
        )
        
        fig.update_xaxes(categoryorder='array', categoryarray=['POSITIVO', 'NEUTRO', 'NEGATIVO'])
        
        st.plotly_chart(fig, use_container_width=True)
        
        # --- S√≠ntese Integrada ---
        st.write("#### S√≠ntese Integrada de Mercado e Sentimentos")
        st.info(latest_analysis['S√≠ntese'])


# --- Se√ß√£o Hist√≥rico ---
st.header("2. Hist√≥rico de An√°lises")
if not history_df.empty:
    st.dataframe(history_df, column_config={
        "resumo_sentimentos": st.column_config.Column(label="S√≠ntese", width="large"),
        "recomendacao": st.column_config.Column(label="Distribui√ß√£o", width="large"),
        "modelo": st.column_config.Column(label="Modelo"),
        "data_geracao": st.column_config.DatetimeColumn(label="Data Gera√ß√£o")
    }, use_container_width=True)

# --- Se√ß√£o Comparativo (DIN√ÇMICO) ---
st.header("3. Compara√ß√£o de Modelos Selecionados")

if not history_df.empty:
    
    # 1. Identifica os modelos √∫nicos na ordem de an√°lise mais recente (necessita da coluna 'modelo' em min√∫sculo)
    distinct_models = history_df['modelo'].unique()
    
    # 2. Pega os dois modelos distintos mais recentes
    if len(distinct_models) < 2:
        st.warning("Execute a an√°lise para pelo menos dois modelos diferentes para exibir a compara√ß√£o.")
    else:
        # Pega os dois primeiros modelos mais recentes do array de distintos
        modelo_a = distinct_models[0]
        modelo_b = distinct_models[1]

        # Busca a an√°lise mais recente para cada um
        analysis_a = get_latest_analysis(history_df, modelo_a)
        analysis_b = get_latest_analysis(history_df, modelo_b)
        
        # S√≥ exibe se ambos tiverem dados v√°lidos
        if analysis_a and analysis_b:
            col_a, col_b = st.columns(2)
            
            with col_a:
                st.markdown(f"**Modelo: {analysis_a['Modelo']}**")
                st.markdown(f"**√öltima An√°lise:** {analysis_a['Data']}")
                st.info(analysis_a['Distribui√ß√£o'])
                st.markdown(f"**S√≠ntese de Sentimentos:**")
                st.caption(analysis_a['S√≠ntese'])

            with col_b:
                st.markdown(f"**Modelo: {analysis_b['Modelo']}**")
                st.markdown(f"**√öltima An√°lise:** {analysis_b['Data']}")
                st.info(analysis_b['Distribui√ß√£o'])
                st.markdown(f"**S√≠ntese de Sentimentos:**")
                st.caption(analysis_b['S√≠ntese'])
        else:
             st.warning(f"N√£o foi poss√≠vel buscar a √∫ltima an√°lise para os modelos '{modelo_a}' e '{modelo_b}'. Tente executar as an√°lises novamente.")
